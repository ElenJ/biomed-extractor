TODO: this is a basic template for a model selection document. Please fill in the details as per your project requirements and once you have finalized the model selection process.



# Model Selection Process and Rationale

**Project:** Biomedical LLM Information Extraction Tool  
**Version:** 0.1  
**Author:** [Your Name]  
**Date:** [Date]



## 1. Introduction

This document details the process and rationale behind the selection of NLP models used for information extraction and summarization in the Biomedical LLM Information Extraction Tool. The goal is to ensure effective, accurate extraction of clinical trial key elements (such as Population, Intervention, Comparator, and Outcomesâ€”PICO) from complex, domain-specific text.



## 2. Model Selection Criteria

To choose the appropriate models, the following criteria were considered:

- **Domain Adaptation:** Preference for models pre-trained or fine-tuned on biomedical or clinical corpora (higher accuracy in life science language).
- **Task Suitability:** Support for Named Entity Recognition (NER), sequence labeling, and abstractive summarization.
- **Scalability and Deployment:** Ability to run inference efficiently on CPUs or modest GPUs with reasonable latency, supporting Dockerized/local operation.
- **Community and Documentation:** Open-source models with active support and robust documentation.
- **Extensibility:** Models that are easily updatable or replaceable as research progresses or needs change.
- **Privacy:** Option to operate entirely offline, without mandatory API calls to external services, for use in high-compliance environments.



## 3. Models Considered

### 3.1 General-Purpose Transformer Models

- **BERT (base, uncased)**
- **RoBERTa**
- **GPT-2, GPT-3 (API-based)**

While general transformers set a strong baseline in NLP, they lack specialization in medical or clinical language, and may underperform in recognizing domain-specific concepts.



### 3.2 Biomedical/Clinical Pre-trained Models

- **BioBERT** ([Lee et al., 2019](https://arxiv.org/abs/1901.08746))
- **ClinicalBERT**
- **SciBERT**
- **BlueBERT**
- **PubMedBERT**
- **BioMegatron**

These models are pre-trained or further pre-trained on large biomedical literature, clinical notes, or PubMed abstracts, which makes them ideal for accurate NER and relation extraction in clinical trial documentation.



### 3.3 Summarization Models

- **SciBERT + Simple Head** (for extractive summaries)
- **T5-base (pre-trained or biomedical variants)**
- **BioGPT** (for open-ended summarization)

Biomedical versions of T5 and GPT models, trained on PubMed data or similar, are better at abstracting long-form text into concise, clinically meaningful summaries.



## 4. Selected Models

### 4.1 Information Extraction (PICO Elements & NER)

**Primary Model:**  
- **BioBERT-base-v1.1** (or similar biomedical NER model)
- Rationale:  
  - Proven state-of-the-art performance in biomedical NER tasks.
  - Readily available in the Huggingface Transformers ecosystem.
  - Sufficiently efficient for local inference.

**Fallback/Secondary Models:**  
- **ClinicalBERT** for datasets with more clinical narrative.
- **SciSpacy** (for lightweight rule-based/NER tasks or as pre/post-processing).



### 4.2 Summarization

**Primary Model:**  
- **BioGPT** or **T5-base (BioMed fine-tuned)**
- Rationale:  
  - Supports abstractive summarization, works well for long and technical text.
  - Readily available for on-premise deployment, with open weights.



## 5. Model Evaluation and Decision Process

- Conducted small-scale comparative tests on sample ClinicalTrials.gov documents.
- Benchmarked for extraction quality (precision, recall of PICO elements) and summarization coherence/readability.
- Considered ease of integration, compatibility with Streamlit/fast batch inference, and Dockerization.
- Documented performance metrics and qualitative feedback from test users (see `evaluation.md` for details).



## 6. Model Deployment Considerations

- All selected models can be loaded and run within a self-contained Docker image, with no external API dependency for inference.
- Model weights are downloaded on first build/deployment if not included in the image.



## 7. Future Directions

- Evaluate next-generation LLMs (e.g., Bio-LLaMA, Med-PaLM) as they become open source and feasible to run locally.
- Provide user-selectable model options in the interface for specialized use cases.
- Continuously monitor the biomedical NLP literature to update models as standards evolve.



## 8. References

- [BioBERT Paper](https://arxiv.org/abs/1901.08746)
- [BioGPT](https://github.com/microsoft/BioGPT)
- [Huggingface Model Hub](https://huggingface.co/models)
- [PubMedBERT](https://huggingface.co/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract)

